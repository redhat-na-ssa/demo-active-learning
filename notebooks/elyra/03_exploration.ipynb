{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48b41364-8eb9-4ec4-bb4b-dbe923794693",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc75b653-8a19-4b41-a579-ca3a2d32603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# scratch directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "scratch_path = os.environ.get(\"SCRATCH\", \"scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306967e-7ee7-4fe0-8c56-754aed28f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "%pip install -q -U pip\n",
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee5b19-ac16-4e0f-a448-212a8bd4b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, random, pathlib, warnings, itertools, math\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    ")\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "352ef701-1680-44a6-9b2d-420d906ca4f2",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f8ca2-b0f0-451d-9ced-d228d0f74905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup paths for data\n",
    "dataset = scratch_path + \"/Vegetable Images/\"\n",
    "\n",
    "train_folder = os.path.join(dataset, \"train\")\n",
    "test_folder = os.path.join(dataset, \"validation\")\n",
    "validation_folder = os.path.join(dataset, \"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af4180d0-2b0b-49c9-9ed6-26829ed3e10e",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846d1cd-2054-4812-bfa9-9b2df3082fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(rootdir):\n",
    "    \"\"\"counts the number of files in each subfolder in a directory\"\"\"\n",
    "    for path in pathlib.Path(rootdir).iterdir():\n",
    "        if path.is_dir():\n",
    "            print(\n",
    "                \"There are \"\n",
    "                + str(\n",
    "                    len(\n",
    "                        [\n",
    "                            name\n",
    "                            for name in os.listdir(path)\n",
    "                            if os.path.isfile(os.path.join(path, name))\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                + \" files in \"\n",
    "                + str(path.name)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b68f77-dfee-4d0c-93bb-df42eec97c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_files(os.path.join(train_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902f171-356f-4e9f-9a4a-ba22aa7cabe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_files(os.path.join(test_folder))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1033ebe-0314-4cf5-90d6-a0f23149e70d",
   "metadata": {},
   "source": [
    "As evident, Dataset is well balanced with each class containing :\n",
    "1000 images for training set.\n",
    "200 images for test set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecef1b5f-7039-45fe-9d99-02e697cd5f09",
   "metadata": {},
   "source": [
    "# Image Proprocessing\n",
    "\n",
    "The goal of image processing is improvement of pictorial information for human interpretation. Basic manipulation and filtering can lead to increased understanding for feature extraction as well.\n",
    "\n",
    "We increase the color saturation, contrast and finally sharpened the image for drawing texture and viewer focus. The image after processing looks appealing and brighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd82b6-55c9-44d8-87e7-efcb9c785dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"Cucumber\"  # The vegetable you want to display\n",
    "number_of_images = 2  # Number of images to display\n",
    "\n",
    "\n",
    "def Preprocess():\n",
    "    j = 1\n",
    "    for i in range(number_of_images):\n",
    "        folder = os.path.join(test_folder, image_folder)\n",
    "        a = random.choice(os.listdir(folder))\n",
    "\n",
    "        image = Image.open(os.path.join(folder, a))\n",
    "        image_duplicate = image.copy()\n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        plt.subplot(number_of_images, 2, j)\n",
    "        plt.title(label=\"Orignal\", size=17, pad=\"7.0\", loc=\"center\", fontstyle=\"italic\")\n",
    "        plt.imshow(image)\n",
    "        j += 1\n",
    "\n",
    "        image1 = ImageEnhance.Color(image_duplicate).enhance(1.35)\n",
    "        image1 = ImageEnhance.Contrast(image1).enhance(1.45)\n",
    "        image1 = ImageEnhance.Sharpness(image1).enhance(2.5)\n",
    "\n",
    "        plt.subplot(number_of_images, 2, j)\n",
    "        plt.title(\n",
    "            label=\"Processed\", size=17, pad=\"7.0\", loc=\"center\", fontstyle=\"italic\"\n",
    "        )\n",
    "        plt.imshow(image1)\n",
    "        j += 1\n",
    "\n",
    "\n",
    "Preprocess()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c11e6e5-0b1d-48d5-8e87-6be0f5fd7f15",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "\n",
    "We can start exploring the dataset and visualize any class label (for instance, Capsicum). You can choose any vegetable to visualize the images of that class. Changing rows and columns variable also results in different format positioning of matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12e3e6-45fd-43e9-a5b4-f88136439a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_vegetable = \"Capsicum\"\n",
    "rows, columns = 1, 5\n",
    "\n",
    "display_folder = os.path.join(train_folder, select_vegetable)\n",
    "total_images = rows * columns\n",
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "\n",
    "for i, j in enumerate(os.listdir(display_folder)):\n",
    "    img = plt.imread(os.path.join(train_folder, select_vegetable, j))\n",
    "    fig = plt.subplot(rows, columns, i + 1)\n",
    "    fig.set_title(select_vegetable, pad=11, size=20)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    if i == total_images - 1:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "728ddaab-588f-4070-b830-a9687b0146d8",
   "metadata": {},
   "source": [
    "Now let's visualize the whole dataset by picking a random image from each class inside training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eeb0f4-0794-493e-bf02-45b5b8552666",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for food_folder in sorted(os.listdir(train_folder)):\n",
    "    food_items = os.listdir(train_folder + \"/\" + food_folder)\n",
    "    food_selected = np.random.choice(food_items)\n",
    "    images.append(os.path.join(train_folder, food_folder, food_selected))\n",
    "\n",
    "fig = plt.figure(1, figsize=(15, 10))\n",
    "\n",
    "for subplot, image_ in enumerate(images):\n",
    "    category = image_.split(\"/\")[-2]\n",
    "    imgs = plt.imread(image_)\n",
    "    a, b, c = imgs.shape\n",
    "    fig = plt.subplot(3, 5, subplot + 1)\n",
    "    fig.set_title(category, pad=10, size=18)\n",
    "    plt.imshow(imgs)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c96dc865-6a56-4123-b896-471848f347af",
   "metadata": {},
   "source": [
    "There are 15 vegetables (output classes) and one random image from each class helps in determining basic outlook of dataset and what picture quality along with different metric are visible. So far, So Good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae3c1f-a7a7-4d82-8d7a-a2143804d723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
